{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of homework1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B42YV4QyuRKZ",
        "colab_type": "text"
      },
      "source": [
        "# Instructions:\n",
        "## Please save a copy of this notebook to your google drive and answer the questions below.\n",
        "## Once completed please submit your notebook to the following [GitHub Repo](https://github.com/7-gate-academy-ml-program/Synopsis)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8mmOkNLyoWt",
        "colab_type": "text"
      },
      "source": [
        "### Name: Parampaul Nahal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SdkchPgStYin",
        "colab_type": "text"
      },
      "source": [
        "# 1.)  What is the difference between Classification and Regression?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aKWEz_atmEp",
        "colab_type": "text"
      },
      "source": [
        "They both share the goal is function approximation. The key difference lies in the output variable. \n",
        "\n",
        "**Classification**\n",
        "\n",
        "- Output variable is discrete\n",
        "- Simply: Classification predicts specific  class labels\n",
        "- e.g.: Cat vs Dog, Cloudy vs Sunny\n",
        "\n",
        "**Regression**\n",
        "\n",
        "- Output variable is continuous \n",
        "- Simply: Regression predicts (or estimates) a real value quantity. \n",
        "- e.g.: 70% cloudy, $ 34500"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ma7t_7yBtmud",
        "colab_type": "text"
      },
      "source": [
        "# 2.) What is the Curse of Dimensionality?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C3_8rvyyDYA",
        "colab_type": "text"
      },
      "source": [
        "The curse of dimensionality states that the amount of training data required to make meaningful models grows exponentially as you add more dimensions or features linearly. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w_rFydWVyDl3",
        "colab_type": "text"
      },
      "source": [
        "# 3.) What is Cross Validation?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-iA3jnCtxqP",
        "colab_type": "text"
      },
      "source": [
        "To train a model, we split our data into test sets and training sets. The model is then trained on the training set and evaluated with a set that the model has not seen before (the testing set). This method is a very simple split. You can also utilize K-Folds which windows test subsets throughout the entire data set. This is useful to prevent any bias by not leaning on one 'side' of the data too heavily. This also lets the model use more of the input data than a simple train-test split. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieaSLJE2tyVm",
        "colab_type": "text"
      },
      "source": [
        "# 4.) On a high level how do Decision  Trees work?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD6nBEWCt8ud",
        "colab_type": "text"
      },
      "source": [
        "A decision tree uses attributes (nodes) and their values (edges) to traverse a hierarchy  of questions leading to a class label. Generally, the best attribute is chosen to be the first node. We ask a question and follow the answer's path until we get an answer. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6akxVwD_t82G",
        "colab_type": "text"
      },
      "source": [
        "# 5.) In regards to SVMs what is the Kernel Trick?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDGR-lhHuKNq",
        "colab_type": "text"
      },
      "source": [
        "Sometimes we might be faced with data that isn't linearly seperable. The Kernel trick allows us to transform and project our data into a new dimension where it can hopefully then be seperated by a hyperplane. "
      ]
    }
  ]
}